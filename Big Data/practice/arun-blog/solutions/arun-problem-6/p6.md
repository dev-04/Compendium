# Problem 6

## 1. Create hive DB

create a hive meta store database named problem6 and import all tables from mysql retail_db database into hive meta store.

```bash
hive -e "CREATE DATABASE IF NOT EXISTS problem6"
```

```bash
sqoop import-all-tables \
    --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
    --username root \
    --password cloudera \
    --hive-import \
    --hive-overwrite \
    --create-hive-table \
    --hive-database problem6
```

## 2. Hive Metastore in Spark

On spark shell use data available on meta store as source and perform step 3,4,5 and 6. [this proves your ability to use meta store as a source]

```bash
sudo cp /etc/hive/conf/hive-site.xml /etc/spark/conf/
```

## 3. Ranking

Rank products within department by price and order by department ascending and rank descending [this proves you can produce ranked and sorted data on joined data sets]

### Using Spark SQL

```scala
val df = sqlContext.sql("""
    SELECT p.product_id, p.product_category_id, p.product_name, p.product_description, p.product_price, p.product_image, d.department_id, RANK() OVER (PARTITION BY d.department_id ORDER BY p.product_price ASC) rank_department, DENSE_RANK() OVER (PARTITION BY d.department_id ORDER BY p.product_price ASC) dense_rank_department
      FROM problem6.products p, problem6.categories c, problem6.departments d
     WHERE p.product_category_id = c.category_id
       AND c.category_department_id = d.department_id
     ORDER BY d.department_id ASC, rank_department DESC
""")

df.registerTempTable("product_price_rank_temp")
```

### 4. Aggregate statistics

### Using SparkSQL

```scala
val df = sqlContext.sql("""
    SELECT o.order_customer_id, COUNT(DISTINCT(ot.order_item_product_id)) distinct_purchases
      FROM problem6.orders o, problem6.order_items ot
     WHERE ot.order_item_order_id = o.order_id
     GROUP BY o.order_customer_id
     ORDER BY distinct_purchases DESC, o.order_customer_id ASC
     LIMIT 10
""")

df.registerTempTable("customers_top_unique_purchases")
```

### 5. Filter 1

```scala
val df = sqlContext.sql("""
    SELECT *
      FROM product_price_rank_temp
     WHERE product_price < 100
""")
```

### 6. Filter 2

```scala
val df = sqlContext.sql("""
    SELECT tp.order_customer_id, p.product_id, p.product_price
      FROM problem6.orders o, customers_top_unique_purchases tp, problem6.order_items oi, problem6.products p
      WHERE tp.order_customer_id = o.order_customer_id
        AND o.order_id = oi.order_item_order_id
        AND oi.order_item_product_id = p.product_id
        AND p.product_price < 100
""")
```

### 7. Save to Metastore

```scala
df.saveAsTable("problem6.products_purchased_top_customers")
```
