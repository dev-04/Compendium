# P1

## Import orders table

```bash
sqoop import \
    --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
    --username root \
    --password cloudera \
    --table orders \
    --target-dir /user/cloudera/problem1/orders \
    --as-avrodatafile \
    --compress \
    --compression-codec org.apache.hadoop.io.compress.SnappyCodec
```

## Import Order Items table

```bash
sqoop import \
    --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
    --username root \
    --password cloudera \
    --table order_items \
    --target-dir /user/cloudera/problem1/order_items \
    --as-avrodatafile \
    --compress \
    --compression-codec org.apache.hadoop.io.compress.SnappyCodec
```

## Load Avro files in Spark

```scala
import com.databricks.spark.avro._
val orders_df = sqlContext.read.avro("/user/cloudera/problem1/orders")
// Orders [order_id: int, order_date: bigint, order_customer_id: int, order_status: string]

val orderitems_df = sqlContext.read.avro("/user/cloudera/problem1/order_items")
// Order Items [order_item_id: int, order_item_order_id: int, order_(item_product_id: int, order_item_quantity: int, order_item_subtotal: float, order_item_product_price: float]
```

## Compute using dataframe API

```scala
val joinedDF = orders_df.join(orderitems_df, orders_df("order_id") === orderitems_df("order_item_order_id"))

val dataframe_df = joinedDF.groupBy("order_date", "order_status")
    .agg(countDistinct("order_id").as("total_orders"), sum("order_item_subtotal").as("total_amount"))
    .sort(desc("order_date"), asc("order_status"), desc("total_amount"), asc("total_orders"))
    .withColumn("order_date", from_unixtime(col("order_date")/1000, "YYYY-MM-dd"))
```

## Compute using SQL

```scala
orders_df.registerTempTable("orders")
orderitems_df.registerTempTable("order_items")

val sql_df = sqlContext.sql("""
    SELECT to_date(from_unixtime(cast(order_date/1000 as bigint))) as order_date, order_status, count(distinct(order_id)) as total_orders, sum(order_item_subtotal) as total_amount
      FROM orders, order_items
     WHERE order_id = order_item_order_id
     GROUP BY order_date, order_status
     ORDER BY order_date DESC, order_status ASC, total_orders DESC, total_amount ASC
""")
```

## Compute using RDDs

```scala
val orders_rdd = orders_df.rdd
val orderItems_rdd = orderitems_df.rdd

//creates order_id, (order_date, order_status), order_item_subtotal
val joinedRDD = orders_rdd
    .map(x => (x(0).toString, (x(1).toString, x(3).toString))).join(orderItems_rdd.map(y => (y(1).toString, y(4).toString.toFloat)))
    .map{case (id, ((od, os), ost)) => ((od, os), (ost, id))}

val rdd = joinedRDD.combineByKey(
    (x: (Float, String)) => (x._1, Set(x._2)),
    (x: (Float, Set[String]), y: (Float, String)) => (x._1+y._1, x._2 + y._2),
    (x: (Float, Set[String]), y: (Float, Set[String])) => (x._1+y._1, x._2 ++ y._2)
)

val final_df = rdd
    .map{case ((od, os), (x:Float, y: Set[String])) => (od, os, x, y.size)}
    .toDF()
    .orderBy(col("_1").desc, col("_2").asc, col("_3").desc, col("_4").asc)
```

## Save in Parquet GZip compressed

```scala
sqlContext.setConf("spark.sql.parquet.compression.codec", "gzip")
dataframe_df.write.save("/user/cloudera/problem1/result4a-gzip")
sql_df.write.save("/user/cloudera/problem1/result4b-gzip")
final_df.write.save("/user/cloudera/problem1/result4c-gzip")
```

## Save in Parquet Snappy compressed

```scala
sqlContext.setConf("spark.sql.parquet.compression.codec", "snappy")
dataframe_df.write.save("/user/cloudera/problem1/result4a-snappy")
sql_df.write.save("/user/cloudera/problem1/result4b-snappy")
final_df.write.save("/user/cloudera/problem1/result4c-snappy")
```

## Save in CSV format (uncompressed)

```scala
dataframe_df.map(x => x(0) + "," + x(1) + "," + x(2) + "," + x(3)).saveAsTextFile("/user/cloudera/problem1/result4a-csv")
sql_df.map(x => x(0) + "," + x(1) + "," + x(2) + "," + x(3)).saveAsTextFile("/user/cloudera/problem1/result4b-csv")
final_df.map(x => x(0) + "," + x(1) + "," + x(2) + "," + x(3)).saveAsTextFile("/user/cloudera/problem1/result4c-csv")
```

## Export the CSV to mysql table

### Create the mysql table

```bash
mysql -h localhost -u root -p cloudera

use retail_db;
CREATE TABLE order_stats (
    order_status_date VARCHAR(255) NOT NULL,
    order_status VARCHAR(255) NOT NULL,
    total_orders INT,
    total_amount NUMERIC,
    CONSTRAINT pk_order PRIMARY KEY (order_status_date, order_status)
);
```

### Run the Sqoop export

```bash
sqoop export \
    --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
    --username root \
    --password cloudera \
    --table order_stats \
    --export-dir /user/cloudera/problem1/result4a-csv \
    --mysql-delimiters
```